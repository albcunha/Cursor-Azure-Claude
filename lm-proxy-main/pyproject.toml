[project]
name = "lm-proxy"
version = "3.0.2"
description = "LM-Proxy is an OpenAI-compatible http proxy server for inferencing various LLMs capable of working with Google, Anthropic, OpenAI APIs, local PyTorch inference, etc."
readme = "README.md"
keywords = ["llm", "large language models", "ai", "gpt", "openai", "proxy", "http", "proxy-server", "llm gateway", "openai", "anthropic", "google genai"]
classifiers = [
    "Intended Audience :: Developers",
    "Operating System :: OS Independent",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: 3.13",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
    "Intended Audience :: Developers",
    "Topic :: Software Development :: Libraries :: Application Frameworks",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Development Status :: 5 - Production/Stable",
]

requires-python = ">=3.11,<4"

authors = [
    { name = "Vitalii Stepanenko", email = "mail@vitaliy.in" },
]
maintainers = [
    { name = "Vitalii Stepanenko", email = "mail@vitaliy.in" },
    { name = "Nikita Sahaidachnyi", email = "nikita.sahaidachnyi@gmail.com"},
    { name = "Dariia Stepanenko", email = "zozulinadarina97@gmail.com"},
]
homepage = "https://github.com/Nayjest/lm-proxy"
repository = "https://github.com/Nayjest/lm-proxy"
documentation = "https://github.com/Nayjest/lm-proxy#readme"
license = { file = "LICENSE" }

dependencies = [
    "ai-microcore>=5.1.2,<6",
    "fastapi>=0.121.3,<1",
    "uvicorn>=0.41.0",
    "typer>=0.24.0",
    "requests~=2.32.5",
    "pydantic~=2.12.5",
    "websockets>=14.0,<15",  # bugs in v15: invalid syntax (http11.py, line 428)
]

[project.optional-dependencies]
test = [
   "pytest~=8.4.2",
   "pytest-asyncio~=1.2.0",
   "pytest-cov~=7.0.0"
]
google = [
    "google-genai>=1.62.0,<2",
]
anthropic = [
    "anthropic>=0.77,<1",
]
all = [
    "google-genai>=1.62.0,<2",
    "anthropic>=0.77,<1",
]

[project.urls]
"Source Code" = "https://github.com/Nayjest/lm-proxy"
"Bug Tracker" = "https://github.com/Nayjest/lm-proxy/issues"

[project.entry-points."config.loaders"]
toml = "lm_proxy.config_loaders:load_toml_config"
py = "lm_proxy.config_loaders:load_python_config"
yml = "lm_proxy.config_loaders:load_yaml_config"
yaml = "lm_proxy.config_loaders:load_yaml_config"
json = "lm_proxy.config_loaders:load_json_config"


[project.scripts]
lm-proxy = "lm_proxy.app:cli_app"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.poetry]
package-mode = true
packages = [{ include = "lm_proxy"}]

[tool.pytest.ini_options]
asyncio_mode = "auto"
testpaths = [
    "tests",
]
[tool.black]
line-length = 100
